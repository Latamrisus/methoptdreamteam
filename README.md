# Gradient Descent Optimization Algorithms

This project implements and compares different optimization algorithms, including Gradient Descent, Golden Section Search, and Ternary Search, on two functions: 
- `f1`

<img src="https://latex.codecogs.com/gif.latex?f(x, y) = x^2 + y^2 " />

- `f2`

<img src="https://latex.codecogs.com/gif.latex?f(x, y) = x^2 \cdot y^2 \cdot \log{8x^2 + 3y^2}" />

## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes.

### Prerequisites

- Python
- pip

### Installing

A step by step series of examples that tell you how to get a development environment running.

1. Clone the repository
2. Install the required packages using pip:

```bash
pip install -r requirements.txt
```

## Built With

- [Python](https://www.python.org/) - Programming language
- [Matplotlib](https://matplotlib.org/) - Plotting library
- [NumPy](https://numpy.org/) - Scientific computing library
- [SciPy](https://www.scipy.org/) - Scientific computing library

## Authors
- **[Kister Artemii](https://t.me/latamrisus)**
- **[Tovmasian Arman](https://t.me/lilpuzeen)**
- **[Khimchenko Maxim](https://t.me/Khimchenko_Maxim)**
